{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pZj3MDq186s6"
      },
      "outputs": [],
      "source": [
        "!pip install -q streamlit google-generativeai numpy scikit-learn pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.ngrok2 ~/.config/ngrok\n",
        "!pip uninstall -y pyngrok ngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWe2JNcFy29",
        "outputId": "6bb82bfa-1b79-470b-f28c-ead6d85a2a5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyngrok 7.5.0\n",
            "Uninstalling pyngrok-7.5.0:\n",
            "  Successfully uninstalled pyngrok-7.5.0\n",
            "\u001b[33mWARNING: Skipping ngrok as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n"
      ],
      "metadata": {
        "id": "vfuC6Be5F6Wh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyAvIFmH4a4oHHwKy_O95UHR9Qf5VvMlZxc\"\n"
      ],
      "metadata": {
        "id": "XHbZjErN9Ums"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --------------------\n",
        "# CONFIG\n",
        "# --------------------\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "st.set_page_config(page_title=\"Gemini RAG App\", layout=\"wide\")\n",
        "st.title(\"ðŸ“š RAG with Gemini (Free Tier)\")\n",
        "\n",
        "# --------------------\n",
        "# DOCUMENTS\n",
        "# --------------------\n",
        "documents = [\n",
        "    \"RAG stands for Retrieval Augmented Generation.\",\n",
        "    \"Gemini is Google's large language model.\",\n",
        "    \"Embeddings convert text into numerical vectors.\",\n",
        "    \"Cosine similarity is used for semantic search.\",\n",
        "    \"RAG improves accuracy by grounding LLMs.\"\n",
        "]\n",
        "\n",
        "# --------------------\n",
        "# EMBEDDINGS\n",
        "# --------------------\n",
        "@st.cache_resource\n",
        "def embed_documents(docs):\n",
        "    embeddings = []\n",
        "    for doc in docs:\n",
        "        res = genai.embed_content(\n",
        "            model=\"gemini-embedding-001\",\n",
        "            content=doc,\n",
        "            task_type=\"retrieval_document\"\n",
        "        )\n",
        "        embeddings.append(res[\"embedding\"])\n",
        "    return np.array(embeddings)\n",
        "\n",
        "doc_embeddings = embed_documents(documents)\n",
        "\n",
        "def embed_query(query):\n",
        "    res = genai.embed_content(\n",
        "        model=\"gemini-embedding-001\",\n",
        "        content=query,\n",
        "        task_type=\"retrieval_query\"\n",
        "    )\n",
        "    return np.array(res[\"embedding\"])\n",
        "\n",
        "# --------------------\n",
        "# RETRIEVAL\n",
        "# --------------------\n",
        "def retrieve(query, k=3):\n",
        "    q_emb = embed_query(query).reshape(1, -1)\n",
        "    sims = cosine_similarity(q_emb, doc_embeddings)[0]\n",
        "    top_k = sims.argsort()[-k:][::-1]\n",
        "    return [documents[i] for i in top_k]\n",
        "\n",
        "# --------------------\n",
        "# GENERATION\n",
        "# --------------------\n",
        "model = genai.GenerativeModel(\"gemini-pro-x\")\n",
        "\n",
        "def generate_answer(query, context):\n",
        "    prompt = f\"\"\"\n",
        "Use the context below to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\"\"\"\n",
        "    return model.generate_content(prompt).text\n",
        "\n",
        "# --------------------\n",
        "# UI\n",
        "# --------------------\n",
        "query = st.text_input(\"Ask a question:\")\n",
        "\n",
        "if query:\n",
        "    with st.spinner(\"Retrieving documents...\"):\n",
        "        docs = retrieve(query)\n",
        "\n",
        "    st.subheader(\"ðŸ” Retrieved Context\")\n",
        "    for d in docs:\n",
        "        st.write(\"â€¢\", d)\n",
        "\n",
        "    with st.spinner(\"Generating answer...\"):\n",
        "        answer = generate_answer(query, \"\\n\".join(docs))\n",
        "\n",
        "    st.subheader(\"ðŸ¤– Answer\")\n",
        "    st.write(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVsOxWc1C0S5",
        "outputId": "17b77496-4449-475a-adeb-c2e7525e2187"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "0e2--UGLGzgy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"39U29zapI5dOfjPHcYyTamabdaa_4YCpRM67x1zH4FkeZYpyx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UkpfbtxGz5G",
        "outputId": "f22a7673-d972-40f3-9cd7-47d49f04cd04"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app:\", public_url)\n",
        "\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D31Ye2bjDGqb",
        "outputId": "34946701-7145-450d-b0b4-15077e02a930"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app: NgrokTunnel: \"https://sook-soapsudsy-unlicentiously.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', 'app.py']>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Swi0jJwnFuYM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSE03VW_E0tZ"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}